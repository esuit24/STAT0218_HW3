---
title: "Stat_Hw3"
author: "Ellie Suit, Andy Atallah, and Ai Hattori"
date: "2023-10-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Research Question: 
Analyze vehicleSearch before and after George Floyd incident
- Use race, preRace, gender, policePrecinct, reason, problem, lat, long as a predictor variable 


Types of Trees: 
- Decision/Regression Tree (rpart) - simplist model 
- Bagged Trees (ipred) - making a bunch of similar trees with different observations and determining oob 
- Random Forest (randomforest) - making a bunch of weak learners and taking majority vote
- Boosting Trees (xgboost) - making one tree model and predicting the error for a given variable X 



```{r}
# import libraries
library(lubridate)
library(sf)
library(tidyverse)
library(rattle)
library(rpart)
library(ipred) # for bagging
library(caret) # for confusion matrix


# read in csv
stop_data <- read_csv("Minneapolis_Police_Stop_Data.csv")
  
stop_data_factored <- stop_data %>%
  na.omit() %>%
  mutate(time = as_datetime(responseDate),
         reason = factor(reason),
         problem = factor(problem),
         citationIssued = factor(citationIssued),
         personSearch = factor(personSearch),
         vehicleSearch = factor(vehicleSearch),
         preRace = factor(preRace),
         race = factor(race),
         gender = factor(gender),
         policePrecinct = factor(policePrecinct))

stop_data_factored <- stop_data_factored %>%
  mutate(vehicleSearch = case_when(vehicleSearch == 'NO' ~ 0,
                                   vehicleSearch == 'YES' ~ 1),
         personSearch = case_when(personSearch == 'NO' ~ 0,
                                   personSearch == 'YES' ~ 1),
         citationIssued = case_when(citationIssued == 'NO' ~ 0,
                                   citationIssued == 'YES' ~ 1))



```


```{r}
gf_date <- as.Date("2020-05-26")
stop_data_factored <- stop_data_factored %>%
  mutate(case = case_when(time <= gf_date ~ 0,
                          time > gf_date ~ 1)) %>%
  mutate(case = factor(case))

before_gf <- stop_data_factored %>%
  filter(case == 0) 
after_gf <- stop_data_factored %>%
  filter(case == 1)


```
```{r}
table(stop_data_factored$race)
```


# Decision Tree
```{r}
#view(stop_data_factored)

tree <- rpart(personSearch ~ race + gender + policePrecinct + reason + problem + case + lat + long + preRace, data = stop_data_factored) 

#TODO: why does this not work for a binary variable vehicleSearch? 
fancyRpartPlot(tree)

```

```{r}
tree1 <- rpart(vehicleSearch ~ race + gender + policePrecinct + reason + problem + case + lat + long + preRace, data = stop_data_factored) 

#TODO: why does this not work for a binary variable vehicleSearch? 
fancyRpartPlot(tree1)
```

# Random Forest

```{r}
library(randomForest)
rf1 <- randomForest(preRace ~ reason + problem + gender + policePrecinct + night + lat + long, data = stop_data_factored, mtry = 4, importance = TRUE) 

rf2 <- randomForest(race ~ reason + problem  + personSearch + gender + policePrecinct + lat + long, data = stop_data_factored, mtry = 4, importance = TRUE)


view(rf1$importance)

view(rf2$importance) 

rf1
rf2
```


# Bagging

Useful link: https://bookdown.org/tpinto_home/Beyond-Additivity/bagging.html 

## Split data in half to create traininig and testing data

Creating training and testing data allows us to display a confusion matrix for our bagging model.
This is useful because, even if the OOB error is low, there is still a possibility that the model predicts only one class (e.g. NO for Vehicle Searched) for every observation. 

```{r}
set.seed(1)
rows_to_test <- sample(1:nrow(stop_data_factored),
                       size = nrow(stop_data_factored)/2,
                       replace = FALSE) 

test_bag <- stop_data_factored[rows_to_test,]
train_bag <- stop_data_factored[-rows_to_test,]
```

## Predict vehicle search by using all possible predictor variables*

* excluding OBJECTID, masterIncidentNumber, responseDate, callDisposition, x, y, neighborhood, lastUpdatedDate, and time

```{r}
# library(ipred)
# try a single number of bags, 25 (default)
bag_veh <- bagging(vehicleSearch ~ reason + problem + citationIssued + personSearch
                    + preRace + race + gender + lat + long + policePrecinct + case,
                data = train_bag,
                coob = TRUE) # coob: calculate out of bag error

# predict on test data
preds_veh <- predict(bag_temp, test_bag, type = "class")

# confusion matrix
# library(caret)
confusionMatrix(preds_veh, test_bag$vehicleSearch)

# print OOB error
oob_veh <- bag_veh$err
oob_veh
```

Classification accuracy for testing data is 99.02%. OOB error is 4.38%.

### calculate importance of predictor variables for vehicleSearch
```{r}
# library(caret)
# library(scales)
# calculate importance of pred vars in our bagging built based on training data
bag_var_imp_veh <- varImp(bag_veh)
# bag_var_imp <- varImp(bag_temp, scale = TRUE) # didn't work
bag_var_imp_veh

# visualize
barplot(bag_var_imp_veh$Overall,
        names.arg = row.names(bag_var_imp_veh),
        main = "Importance of predictor variables for vehicle search",
        # xlab = "Predictor variable",
        ylab = "Importance",
        las = 2,
        cex.names = 1)

# rescale importance from 0 to 100 and visualize
# bag_var_imp_veh_scaled <- (bag_var_imp_veh$Overall/sum(bag_var_imp_veh$Overall))*100
bag_var_imp_veh_scaled <- bag_var_imp_veh %>%
  mutate(Overall = (Overall/sum(Overall))*100)

barplot(bag_var_imp_veh_scaled$Overall,
        names.arg = row.names(bag_var_imp_veh_scaled),
        main = "Importance of predictor variables for vehicle search",
        ylab = "Importance (%)",
        ylim = c(0,25),
        las = 2, # rotate labels to display all row names
        cex.names = 1)
```

### Find predictor variables that have importance less than 5% for vehicleSearch
```{r}
index_veh <- which(bag_var_imp_veh_scaled$Overall < 5)
rownames(bag_var_imp_veh_scaled)[index_veh]
```


For vehicle search, thus, "case," "citationIssued," and "gender" seem to be the least important for predicting it. 

